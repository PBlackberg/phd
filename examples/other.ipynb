{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset by folder and later combining folders\n",
    "# path_gen = '/g/data/ia39/aus-ref-clim-data-nci/gpcp/data/day/v1-3'\n",
    "# years = range(1996,2023)\n",
    "# folders = [f for f in os.listdir(path_gen) if (f.isdigit() and int(f) in years)]\n",
    "# folders = sorted(folders, key=int)\n",
    "\n",
    "\n",
    "# ds_list = []\n",
    "# for folder in folders:\n",
    "#     path_folder = os.path.join(path_gen, folder)\n",
    "#     files = [f for f in os.listdir(path_folder) if f.endswith('.nc')]\n",
    "#     files = sorted(files, key=lambda x: x[x.index(\"y_d\")+1:x.index(\"_c\")])\n",
    "\n",
    "#     path_fileList = []\n",
    "#     for file in files:\n",
    "#         path_fileList = np.append(path_fileList, os.path.join(path_folder, file))\n",
    "\n",
    "\n",
    "#     ds_year = xr.open_mfdataset(path_fileList, combine='by_coords')\n",
    "#     ds_list.append(ds_year)\n",
    "\n",
    "\n",
    "# ds_concat = xr.concat(ds_list, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and except\n",
    "# folders = []\n",
    "# for f in os.listdir(path_gen):\n",
    "#     try:\n",
    "#         if int(f) in years:\n",
    "#             folders.append(f)\n",
    "#     except ValueError:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using different colors in plots\n",
    "# from cycler import cycler\n",
    "# colors = plt.cm.RdBu(np.linspace(0, 1, 12))\n",
    "# colors = np.roll(colors, -1, axis=0)\n",
    "# #colors = np.concatenate((colors[1:], [colors[0]]))\n",
    "# custom_cycler = cycler(color=colors)\n",
    "# f, ax = plt.subplots(figsize = (25,5))\n",
    "# ax.set_prop_cycle(custom_cycler)\n",
    "\n",
    "# pr_percentileMonthly.plot(ax=ax, x='year', hue='month')\n",
    "# plt.title('high percentile precipitation rate ({}) by month'.format('99'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with values from interpolation from neighbouring gridboxes (numpy)\n",
    "# scipy.interpolate.griddata(points, values, xi, method='linear', fill_value=nan, rescale=False)\n",
    "\n",
    "\n",
    "# Interpolate the missing values with interpolate_na\n",
    "# data_interp = data.interpolate_na(dim = 'lat', method='polynomial', order=2)\n",
    "# data_interp[0,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating gif with imagemagick\n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "# for i in range(4):\n",
    "#     print(home + f'/Documents/data/cmip5/animations/Python_Animation_frame_{i:04}.png')\n",
    "\n",
    "\n",
    "# lat = precip.lat\n",
    "# lon = precip.lon\n",
    "# lonm,latm = np.meshgrid(lon,lat)\n",
    "\n",
    "\n",
    "# for i, x in enumerate(x2[0:5]):\n",
    "#     fig= plt.figure(figsize=(20,7.5))\n",
    "#     ax = fig.add_subplot(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "\n",
    "#     ax.add_feature(cfeat.COASTLINE)\n",
    "#     ax.set_extent([lon[0], lon[-1], lat[0], lat[-1]], crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "#     pr_day = precip.isel(time=x[0])\n",
    "#     extreme_percentile_day = pr_percentiles[percentile_option].isel(time=x[0]).data\n",
    "\n",
    "#     pcm= ax.pcolormesh(lonm,latm, pr_day.where(pr_day>conv_threshold),transform=ccrs.PlateCarree(),zorder=0, cmap='Blues')\n",
    "#     ax.pcolormesh(lonm,latm, pr_day.where(pr_day>extreme_percentile_day),transform=ccrs.PlateCarree(), cmap='Reds')\n",
    "\n",
    "\n",
    "#     ax.set_title(model + ': location of precipitation extremes')\n",
    "#     ax.set_xlabel('longitude')\n",
    "#     ax.set_ylabel('latitude')\n",
    "\n",
    "#     ax.set_yticks([-20, 0, 20])\n",
    "#     ax.set_xticks([-180, -90, 0, 90, 180])\n",
    "#     ax.set_xticklabels([0, 90, 180, 270, 360])\n",
    "\n",
    "#     plt.colorbar(pcm, ax=ax, orientation='horizontal',pad=0.10, aspect=50, fraction=0.055, label = percentile_option + ' [mm/day]')\n",
    "#     string = home + f'/Documents/data/cmip5/animations/Python_Animation_frame_{i:04}.png'\n",
    "#     plt.savefig(string)\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "# !convert /Users/cbla0002/Documents/data/cmip5/animations/Python_Animation_frame_*png /Users/cbla0002/Documents/data/cmip5/animations/Python_Animation.gif\n",
    "# display(HTML(\"<img src='/Users/cbla0002/Documents/data/cmip5/animations/Python_Animation.gif' />\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset.resample(freq, dim, how='mean', skipna=None, closed=None, label=None, base=0, keep_attrs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveit=False\n",
    "# if saveit:\n",
    "#     folder = '/Users/cbla0002/Documents/data/cmip6/' + model\n",
    "#     fileName = model + '_adv_tMean_' + experiment_id + '.nc'\n",
    "#     dataset = xr.Dataset({'adv_tMean': adv_tMean})\n",
    "#     save_file(dataset, folder, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection = ccrs.PlateCarree(central_longitude=180)\n",
    "# f, ax = plt.subplots(nrows = 2, ncols=3, subplot_kw=dict(projection=projection), figsize=(25, 10))\n",
    "# plot_axMap(ax[0][0], (mse_anom**2).mean(dim=('time')), 'viridis', 'h\\'^2', model)\n",
    "# plot_axMap(ax[0][1], netlw_corr.mean(dim=('time')), 'viridis', 'h\\' netLW', model)\n",
    "# plot_axMap(ax[0][2], netsef_corr.mean(dim=('time')), 'viridis', 'h\\' netSEF', model)\n",
    "# plot_axMap(ax[1][0], netsw_corr.mean(dim=('time')), 'viridis', 'h\\' netSW', model)\n",
    "# plot_axMap(ax[1][1], adv_corr.mean(dim=('time')), 'viridis', 'h\\' adv', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass weighted vertical integral\n",
    "# /mse.plev.data[0], # units of g/kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting chucksizes for saving\n",
    "#del netsef.encoding['chunksizes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xarray.DataArray.chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = '/Users/cbla0002/Documents/data' + model\n",
    "# fileName = model + '_pr4_historical.nc'\n",
    "# path = folder + '/' + fileName\n",
    "# ds_local = xr.open_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (figsize = (aspect * size, size), faceted plots (and trellis plot): xarray.plot.FacetGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def map_subplot(var, axes):\n",
    "# projection = ccrs.PlateCarree(central_longitude=180)\n",
    "# var.plot(ax=axes, transform=ccrs.PlateCarree(), levels =4, colors = ['w','c','k'], add_colorbar=False) \n",
    "# ax1.add_feature(cfeat.COASTLINE)\n",
    "# ax1.set_extent([lon[0], lon[-1], lat[0], lat[-1]], crs=ccrs.PlateCarree())\n",
    "# ax1.set_title('Snapshot, model:' + model + ' exp:' + experiment)\n",
    "# ax1.set_xticks([-180, -90, 0, 90, 180])\n",
    "# ax1.set_xticklabels([0, 90, 180, 270, 360])\n",
    "# ax1.set_yticks([-20, 0, 20])\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "# All snapshots\n",
    "#f, axs = plt.subplots(nrows = 6, ncols = 2, subplot_kw=dict(projection=projection), figsize=(15, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine files\n",
    "# concatenate files\n",
    "#\n",
    "# fileName = model + '_mse_' + experiment_id + '_1986.nc'\n",
    "# path = folder + '/' + fileName\n",
    "# ds = xr.open_dataset(path)\n",
    "# mse = xr.concat([mse, ds.mse_year], dim=\"time\")\n",
    "\n",
    "\n",
    "# combining datasets\n",
    "# folder = '/Users/cbla0002/Documents/data/cmip6'\n",
    "# fileName = 'MPI-ESM1-2-HR_mse_historical_1970_1986.nc'\n",
    "# path = folder + '/' + fileName\n",
    "# ds = xr.open_dataset(path)\n",
    "# ds\n",
    "\n",
    "# folder = '/Users/cbla0002/Documents/data/cmip6'\n",
    "# fileName = 'MPI-ESM1-2-HR_mse_historical_1987_1999.nc'\n",
    "# path = folder + '/' + fileName\n",
    "# ds2 = xr.open_dataset(path)\n",
    "# ds2\n",
    "\n",
    "# the days from 1st of jan to 30th of jan is missing from 1987\n",
    "\n",
    "\n",
    "# mse = xr.concat([mse, ds.isel(time=slice(0,30)).mse_year], dim=\"time\")\n",
    "# mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax={}\n",
    "# for i in range(4):\n",
    "#     ax[i] = plt.subplot(2,2,i+1)\n",
    "\n",
    "# tas.plot.pcolormesh(ax=ax[0])\n",
    "# tas.plot.imshow(ax=ax[1])\n",
    "# tas.plot.contourf(ax=ax[2])\n",
    "# tas.plot.contour(ax=ax[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cartopy.crs as ccrs\n",
    "\n",
    "# ax = [\n",
    "#     plt.subplot(121, projection=ccrs.Orthographic()),\n",
    "#     plt.subplot(122, projection=ccrs.Orthographic(central_longitude=90)),\n",
    "# ]\n",
    "\n",
    "# ax[0].set_title('pcolormesh')\n",
    "# tas.plot.pcolormesh(ax=ax[0], transform=ccrs.PlateCarree(), add_colorbar=False, add_labels=False)\n",
    "# ax[0].coastlines()\n",
    "\n",
    "# ax[1].set_title('imshow')\n",
    "# tas.plot.imshow(ax=ax[1], transform=ccrs.PlateCarree(), add_colorbar=False, add_labels=False)\n",
    "# ax[1].coastlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "\n",
    "# fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "# # Setup axes\n",
    "# gs = gridspec.GridSpec(2,4)\n",
    "# axs = {}\n",
    "# axs['annual'] = fig.add_subplot(gs[0:2,0:2])\n",
    "# axs['DJF'] = fig.add_subplot(gs[0,2])\n",
    "# axs['JJA'] = fig.add_subplot(gs[1,2])\n",
    "# axs['MAM'] = fig.add_subplot(gs[0,3])\n",
    "# axs['SON'] = fig.add_subplot(gs[1,3])\n",
    "\n",
    "# # Disable axis ticks\n",
    "# for ax in axs.values():\n",
    "#     ax.tick_params(bottom=False, labelbottom=False, left=False, labelleft=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matplotlib plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to plot axes\n",
    "# fig, axes = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "#ds.air.plot(ax=axes[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map plot 2 \n",
    "# fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(25,10), subplot_kw={'projection': ccrs.PlateCarree(central_longitude=180)}) #,layout=\"constrained\")\n",
    "# extent= [lon[0], lon[-1], lat[0], lat[-1]]\n",
    "# #cmap= mpl.get_cmap('Blues')\n",
    "# #norm= cm.colors.LogNorm(vmin=0,vmax=15)\n",
    "\n",
    "# i=0\n",
    "# for row in axes:\n",
    "#     for col in row:\n",
    "#         if i==19:\n",
    "#             break\n",
    "        \n",
    "#         fileName = insts[i] + '_' + var_file[0] + '_' + var[0] + '_' + scenario[0] \n",
    "#         file_path = os.path.abspath(os.path.join(data_path, percentile[0], var_file[0], fileName))\n",
    "#         data = loadmat(file_path)\n",
    "#         z = data['mean_pr_image']\n",
    "#         z = np.transpose(z)\n",
    "#         col.add_feature(cfeat.COASTLINE)\n",
    "#         col.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "#         pcm= col.pcolormesh(lon2d,lat2d,z,transform=ccrs.PlateCarree(),zorder=0) #,cmap=cmap)\n",
    "\n",
    "#         col.set_title(insts[i] + ' ' + 'pr_mean ' + scenario[0])\n",
    "#         #col.set_xticks([-180, -90, 0, 90, 180])\n",
    "#         col.set_yticks([-15, 0, 15])\n",
    "\n",
    "#         i+=1\n",
    "#         if i<17:\n",
    "#             cbar= fig.colorbar(pcm,ax=col, orientation='horizontal')\n",
    "#         else:\n",
    "#             cbar= fig.colorbar(pcm,ax=col, orientation='horizontal', label='precipitation (mm/day)')\n",
    "\n",
    "\n",
    "#fig.tight_layout()\n",
    "\n",
    "# plt.savefig('C:/Users/carlp/Desktop/map.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map plot 1\n",
    "# plot figure map\n",
    "# fig= plt.figure(figsize=(15,5))\n",
    "\n",
    "# ax= fig.add_subplot(1,1,1, projection=ccrs.PlateCarree(central_longitude=180)) # central_longitude=180)\n",
    "# #ax.contourf(lon,lat,z)\n",
    "\n",
    "# ax.pcolormesh(lon2d,lat2d,z,transform=ccrs.PlateCarree())\n",
    "# ax.add_feature(cfeat.COASTLINE)\n",
    "# ax.set_extent([lon[0], lon[-1], lat[0], lat[-1]], crs=ccrs.PlateCarree())\n",
    "\n",
    "#ax.set_xlim(lon[0], lon[-1])\n",
    "#ax.set_ylim(lat[0], lat[-1])\n",
    "\n",
    "# divider = make_axes_locatable(ax)\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# plt.colorbar(pcm, cax=cax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting parameters and grid\n",
    "\n",
    "# # plt.rcParams['figure.figsize']=(15.5), you can also do this as a stylesheet\n",
    "# # from matplotlib import style\n",
    "# # style.use('dark_background')\n",
    "# # https://matplotlib.org/3.1.0/gallery/...\n",
    "# # you can define your own parameters, like fontsize, etc as a style\n",
    "\n",
    "# # subplots with plt.subplot2grid((r,c),(start,point), rowspan=, colspan=)\n",
    "# #plt.subplots(layout=\"constrained\")\n",
    "# # plt.tight_layout\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math inside two $$ as well makes it inline mode\n",
    "# \\partial gives delta for partial derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading matlab files\n",
    "# from scipy.io import loadmat\n",
    "# data = loadmat(file_path)\n",
    "# print(data.keys())\n",
    "# lon = np.squeeze(data['lon'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time operations\n",
    "# import timeit\n",
    "#     start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#    print('model: {} took {} minutes to finsih'.format(model, (stop-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_pr[\"time.month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average position of objects for a day, considering 360-0 boundary lon position for objects crossing the boundary\n",
    "\n",
    "#     o_lat = np.append(o_lat, np.sum(obj3d * latm, axis=(0,1)) / np.sum(obj3d, axis=(0,1)))\n",
    "\n",
    "\n",
    "#     # The average lon of objects crossing the boundary must consider jump from 360 to 0\n",
    "#     o_lonDay = np.sum(obj3d * lonm, axis=(0,1)) / np.sum(obj3d, axis=(0,1))\n",
    "\n",
    "#     if not obj3d[:,0,:]==0 or obj3d[:,-1,:]==0:\n",
    "#         idx_change = np.argwhere((np.sum(obj3d[:,0,:],axis=0)>0) * ((np.sum(obj3d[:,0,:],axis=0)>0)))\n",
    "\n",
    "\n",
    "#         # add 360 to half of the domain, take the average, and then subtract again\n",
    "#         idx = int(len(lon)/2)\n",
    "#         lonm_mod = np.append(lonm(:,0:int(len(lon)/2),:)+360,latm(:,int(len(lon)/2):,:)\n",
    "#         o_lonDay[idx_change] = np.sum(obj3d * lonm_mod, axis=(0,1)) / np.sum(obj3d, axis=(0,1)) \n",
    "#         o_lonDay[idx_change] = o_lon[idx_change]  - (o_lon[idx_change]<0)*360\n",
    "\n",
    "#     o_lon = np.append(o_lon, o_lonDay)\n",
    "\n",
    "\n",
    "# o_lat = xr.DataArray(o_lat, attrs=dict(description=\"average latitude of object\", units=\"deg\"))\n",
    "# o_lon = xr.DataArray(o_lon, attrs=dict(description=\"average longitude of object\", units=\"deg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mass weighted vertical integral\n",
    "# F = m * a\n",
    "# pressure force, P, is phrased as per unit area:\n",
    "# P = mass * gravity / (unit area)\n",
    "\n",
    "# so to get the total mass of the column air in gridbox\n",
    "# mass = P_surface * g * area of gridbox\n",
    "\n",
    "# total mass of atmosphere in tropics is:\n",
    "# mass_tropics = sum(P_surface * g * area of gridbox)_for each gridbox \n",
    "\n",
    "# for the mass in each layer we have:\n",
    "# mass = dP * g * area of gridbox\n",
    "\n",
    "# (technically, the area of the subsequent laters of the atmosphere are larger than the surface gidbox area)\n",
    "\n",
    "# mass weighted vertical integral (use trapezoid or simpson's rule to estimate what the average specific humidity is between the layers based on the boundary values)\n",
    "# mass weighted specific humidity = (dP * g * hus * area of gridbox) / P_surface * g * area of gridbox\n",
    "# mass weighted specific humidity = (dP * hus) / P_surface\n",
    "\n",
    "# precipitable water = dP * hus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if number is odd \n",
    "# # a = 2\n",
    "\n",
    "# if a % 2==1:\n",
    "#     print('executes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for regridder xesmf\n",
    "# \n",
    "# # Alternatively \n",
    "# (redefine bounds as in the documentation)\n",
    "# lon1, lon2 = zip(*ds_orig.lon_bnds)\n",
    "# lon1 = list(lon1)\n",
    "# lon2 = list(lon2)\n",
    "# lon_b = np.append(lon1[0], lon2)\n",
    "\n",
    "# lat1, lat2 = zip(*ds_orig.lat_bnds)\n",
    "# lat1 = list(lat1)\n",
    "# lat2 = list(lat2)\n",
    "# lat_b = np.append(lat1[0], lat2)\n",
    "\n",
    "# grid_in={'lon':ds_orig.lon,'lat':ds_orig.lat, \n",
    "#           'lon_b':lon_b,'lat_b':lat_b}\n",
    "\n",
    "\n",
    "# lon1, lon2 = zip(*ds_regrid.lon_bnds)\n",
    "# lon1 = list(lon1)\n",
    "# lon2 = list(lon2)\n",
    "# lon_b = np.append(lon1[0], lon2)\n",
    "\n",
    "# lat1, lat2 = zip(*ds_regrid.lat_bnds)\n",
    "# lat1 = list(lat1)\n",
    "# lat2 = list(lat2)\n",
    "# lat_b = np.append(lat1[0], lat2)\n",
    "\n",
    "# grid_out={'lon':ds_regrid.lon,'lat':ds_regrid.lat, \n",
    "#           'lon_b':lon_b,'lat_b':lat_b}\n",
    "\n",
    "# regrid = xe.Regridder(ds_orig, ds_regrid, 'conservative', periodic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# areaweighting\n",
    "# weights = np.cos(np.deg2rad(lat))$\n",
    "# weights.name = \"weights\"\n",
    "# pr_tMean.weighted(weights).mean(dim=('lat','lon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for True/False dict\n",
    "# import collections\n",
    "# switch = collections.defaultdict(lambda: False, metricFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PBS jobs\n",
    "# not sure what this means: +scratch/k10\n",
    "# how large to use hugemem or megamem ?\n",
    "##PBS -l jobfs=20GB ## parallellisation (local disk on a compute node)\n",
    "\n",
    "\n",
    "# directories to use\n",
    "# data: /g/data/al33/replicas/CMIP5/combined/\n",
    "# scipts run from: /g/data/k10/cb4968/phd/cmip5_scripts\n",
    "# anaconda environemt: /g/data/hh5/public/modules/conda/analysis3-unstable\n",
    "\n",
    "# general\n",
    "# the bash line needs to be on line 1\n",
    "# remove spaces between + and =\n",
    "\n",
    "# \n",
    "\n",
    "# Queues\n",
    "# express, normal, copyq(internet access), hugemem, megamem, gpuvolta(volta gpu) \n",
    "\n",
    "# submitting\n",
    "# submitting job: qsub cmip5_scripts/bash/cmip5_job.sh \n",
    "# check status: qstat -swx jobID (or qstat -s)\n",
    "# check utilisation rate (%gpu): nqstat_anu jobID\n",
    "# remove job from queue: qdel jobID \n",
    "# \n",
    "\n",
    "# > /g/data/k10/cb4968/phd/cmip5_scripts/bash/$PBS_JOBID.log #project for cmip5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module from different folders\n",
    "# \n",
    "# \n",
    "# from parent folder\n",
    "#  from ... import file\n",
    "#\n",
    "#\n",
    "# from subfolder\n",
    "# from folder.file import file\n",
    "#\n",
    "#\n",
    "#  \n",
    "# \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find nans\n",
    "# np.argwhere(np.isnan(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressing file when saving\n",
    "# ds.to_netcdf('ds_compressed.nc', encoding=ds.encoding.update({'zlib': True, 'complevel': 4}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many GB\n",
    "#print(pr_big.nbytes / 1024 ** 3, 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating large dataset with custom time\n",
    "\n",
    "# time_range = pd.date_range(\"1970/01/01\",\"2000/01/01\",freq='D',inclusive='left') # 30 years of daily data\n",
    "\n",
    "# mse_day = mse.isel(time=0)\n",
    "# mse_day = np.expand_dims(mse_day, axis=0)\n",
    "# array = np.ones(shape = (len(time_range), len(mse.plev), len(mse.lat), len(mse.lon)))\n",
    "# mse_big = array * mse_day\n",
    "# np.shape(mse_big)\n",
    "\n",
    "# mse_big = xr.DataArray(\n",
    "#                     data=mse_big,\n",
    "#                     dims=['time','plev','lat', 'lon'],\n",
    "#                     coords={'time': time_range, 'plev':mse.plev.data, 'lat': mse.lat.data, 'lon': mse.lon.data}\n",
    "# )\n",
    "\n",
    "# mse_vInt = xr.DataArray(\n",
    "#     data=-scipy.integrate.simpson(mse_big.data, mse_big.plev.data, axis=1, even='last')/mse_big.plev.data[0], # units of g/kg\n",
    "#     dims=['time','lat', 'lon'],\n",
    "#     coords={'time': mse_big.time.data, 'lat': mse_big.lat.data, 'lon': mse_big.lon.data}\n",
    "#     ,attrs={'units':''}\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
